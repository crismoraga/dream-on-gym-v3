#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
=============================================================================
DREAM-ON-GYM-V2: Demo de Funciones de Recompensa
=============================================================================

Script de demostraciÃ³n que muestra el comportamiento de las 5 funciones
de recompensa implementadas con visualizaciÃ³n en tiempo real.

Autor: DREAM-ON-GYM-V2 Team
Fecha: 2024
=============================================================================
"""

import os
import sys
import numpy as np

# Configurar paths
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(script_dir))
sys.path.insert(0, project_root)

# Imports de funciones de recompensa
from dreamongymv2.reward_functions import (
    BaselineReward,
    QoTAwareReward,
    MultiObjectiveReward,
    FragmentationAwareReward,
    SpectralEntropyAdaptiveReward,
)


def demo_reward_functions():
    """
    DemostraciÃ³n de las funciones de recompensa con escenarios simulados.
    """
    
    print("\n" + "="*75)
    print("  ðŸŽ® DEMO: Funciones de Recompensa para Redes Ã“pticas ElÃ¡sticas")
    print("="*75)
    
    # Crear instancias
    reward_functions = {
        '1. Baseline': BaselineReward(),
        '2. QoT-Aware': QoTAwareReward(),
        '3. Multi-Objective': MultiObjectiveReward(),
        '4. Fragmentation-Aware': FragmentationAwareReward(),
        '5. Spectral-Entropy (NOVEL)': SpectralEntropyAdaptiveReward(),
    }
    
    # Escenarios de prueba
    scenarios = [
        {
            'name': 'âœ… ConexiÃ³n EXITOSA, Red VACÃA',
            'allocated': True,
            'utilization': 0.1,
            'fragmentation': 0.1,
            'description': 'Caso ideal: asignaciÃ³n exitosa con red casi vacÃ­a'
        },
        {
            'name': 'âœ… ConexiÃ³n EXITOSA, Red MODERADA',
            'allocated': True,
            'utilization': 0.5,
            'fragmentation': 0.3,
            'description': 'AsignaciÃ³n exitosa con carga media'
        },
        {
            'name': 'âœ… ConexiÃ³n EXITOSA, Red CONGESTIONADA',
            'allocated': True,
            'utilization': 0.85,
            'fragmentation': 0.6,
            'description': 'AsignaciÃ³n exitosa bajo alta carga (valioso)'
        },
        {
            'name': 'âŒ ConexiÃ³n BLOQUEADA, Red MODERADA',
            'allocated': False,
            'utilization': 0.5,
            'fragmentation': 0.4,
            'description': 'Bloqueo con carga media (penalizaciÃ³n moderada)'
        },
        {
            'name': 'âŒ ConexiÃ³n BLOQUEADA, Alta FRAGMENTACIÃ“N',
            'allocated': False,
            'utilization': 0.4,
            'fragmentation': 0.8,
            'description': 'Bloqueo por fragmentaciÃ³n (penalizaciÃ³n adicional)'
        },
    ]
    
    # Evaluar cada escenario
    for scenario in scenarios:
        print(f"\n{'â”€'*75}")
        print(f"  ðŸ“‹ Escenario: {scenario['name']}")
        print(f"     {scenario['description']}")
        print(f"     UtilizaciÃ³n: {scenario['utilization']:.0%} | "
              f"FragmentaciÃ³n: {scenario['fragmentation']:.0%}")
        print(f"{'â”€'*75}")
        
        results = []
        
        for name, reward_fn in reward_functions.items():
            if hasattr(reward_fn, 'reset_episode'):
                reward_fn.reset_episode()
            
            r = reward_fn.calculate(
                allocated=scenario['allocated'],
                utilization=scenario['utilization'],
                fragmentation=scenario['fragmentation'],
                network=None
            )
            results.append((name, r))
            
            # Barra visual
            bar_len = int(abs(r) * 20)
            if r >= 0:
                bar = 'â–ˆ' * bar_len + 'â–‘' * (20 - bar_len)
                color_indicator = 'ðŸŸ¢'
            else:
                bar = 'â–‘' * (20 - bar_len) + 'â–ˆ' * bar_len
                color_indicator = 'ðŸ”´'
            
            print(f"     {name:<30} {color_indicator} R = {r:+.4f} [{bar}]")
        
        # Ranking
        results_sorted = sorted(results, key=lambda x: x[1], reverse=True)
        print(f"\n     ðŸ† Ranking: ", end="")
        for i, (name, r) in enumerate(results_sorted[:3]):
            medals = ['ðŸ¥‡', 'ðŸ¥ˆ', 'ðŸ¥‰']
            print(f"{medals[i]} {name.split('.')[1].strip()[:15]} ({r:+.2f}) ", end="")
        print()
    
    # Tabla comparativa final
    print("\n" + "="*75)
    print("  ðŸ“Š TABLA COMPARATIVA FINAL")
    print("="*75)
    
    print(f"\n{'FunciÃ³n':<25} â”‚ {'Exitosa (baja carga)':^18} â”‚ {'Exitosa (alta carga)':^18} â”‚ {'Bloqueada':^18}")
    print("â”€"*85)
    
    for name, reward_fn in reward_functions.items():
        # Caso exitoso, baja carga
        reward_fn.reset_episode() if hasattr(reward_fn, 'reset_episode') else None
        r1 = reward_fn.calculate(allocated=True, utilization=0.1, fragmentation=0.1, network=None)
        
        # Caso exitoso, alta carga
        reward_fn.reset_episode() if hasattr(reward_fn, 'reset_episode') else None
        r2 = reward_fn.calculate(allocated=True, utilization=0.8, fragmentation=0.5, network=None)
        
        # Caso bloqueado
        reward_fn.reset_episode() if hasattr(reward_fn, 'reset_episode') else None
        r3 = reward_fn.calculate(allocated=False, utilization=0.5, fragmentation=0.5, network=None)
        
        short_name = name.split('.')[1].strip()
        print(f"{short_name:<25} â”‚ {r1:^+18.4f} â”‚ {r2:^+18.4f} â”‚ {r3:^+18.4f}")
    
    # CaracterÃ­sticas de cada funciÃ³n
    print("\n" + "="*75)
    print("  ðŸ“ CARACTERÃSTICAS DE CADA FUNCIÃ“N")
    print("="*75)
    
    characteristics = {
        'Baseline': [
            'â€¢ Recompensa binaria simple: +1 (Ã©xito) / -1 (bloqueo)',
            'â€¢ FÃ¡cil de interpretar y depurar',
            'â€¢ No considera el estado de la red',
            'â€¢ Ideal como punto de referencia (baseline)',
        ],
        'QoT-Aware': [
            'â€¢ Considera calidad de transmisiÃ³n (OSNR)',
            'â€¢ Penaliza distancias largas',
            'â€¢ Bonifica modulaciones eficientes',
            'â€¢ Ideal para redes sensibles a calidad de seÃ±al',
        ],
        'Multi-Objective': [
            'â€¢ Combina mÃºltiples objetivos con pesos',
            'â€¢ Balance: Blocking (0.5) + FragmentaciÃ³n (0.2) + Throughput (0.3)',
            'â€¢ Personalizable segÃºn prioridades',
            'â€¢ Recomendado para entrenamiento estable',
        ],
        'Fragmentation-Aware': [
            'â€¢ Enfocado en minimizar fragmentaciÃ³n espectral',
            'â€¢ Usa tanto fragmentaciÃ³n externa como interna',
            'â€¢ Incentiva uso contiguo del espectro',
            'â€¢ Mejora eficiencia a largo plazo',
        ],
        'Spectral-Entropy (NOVEL)': [
            'â€¢ ðŸ†• INNOVACIÃ“N: Basada en entropÃ­a de Shannon',
            'â€¢ Sistema de zonas adaptativas (baja/media/alta/crÃ­tica)',
            'â€¢ Bonificaciones dinÃ¡micas segÃºn estado de red',
            'â€¢ Comportamiento emergente sofisticado',
        ],
    }
    
    for name, chars in characteristics.items():
        print(f"\n  ðŸ“Œ {name}:")
        for char in chars:
            print(f"     {char}")
    
    # FÃ³rmulas matemÃ¡ticas
    print("\n" + "="*75)
    print("  ðŸ“ FORMULACIONES MATEMÃTICAS")
    print("="*75)
    
    print("""
  1ï¸âƒ£ Baseline:
     R = +1  si asignada
     R = -1  si bloqueada

  2ï¸âƒ£ QoT-Aware:
     R = w_base Ã— R_base + w_qot Ã— R_qot + w_dist Ã— penalty_dist

  3ï¸âƒ£ Multi-Objective:
     R = Î£(w_i Ã— R_i)  donde i âˆˆ {blocking, fragmentation, throughput}

  4ï¸âƒ£ Fragmentation-Aware:
     R = R_base - Î± Ã— F_ext - Î² Ã— F_int + Î³ Ã— (1 - F_total)

  5ï¸âƒ£ Spectral-Entropy (NOVEL):
     H = -Î£ p_i Ã— logâ‚‚(p_i)          (EntropÃ­a de Shannon)
     zona = clasificar(H)             (baja/media/alta/crÃ­tica)
     R = R_base + bonus(zona) - penalty(zona)
    """)
    
    print("="*75)
    print("  âœ… DEMO COMPLETADA")
    print("="*75)
    print(f"\n  ðŸ“ GrÃ¡ficos disponibles en: {os.path.join(script_dir, 'plots')}")
    print(f"  ðŸ“„ DocumentaciÃ³n completa en: {os.path.join(script_dir, 'DOCUMENTATION.md')}")
    print()


if __name__ == '__main__':
    demo_reward_functions()
