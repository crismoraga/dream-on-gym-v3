#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
=============================================================================
DREAM-ON-GYM-V2: EvaluaciÃ³n RÃ¡pida con Visualizaciones
=============================================================================

Script de evaluaciÃ³n rÃ¡pida que genera comparativas y grÃ¡ficos de las
funciones de recompensa implementadas.

EjecuciÃ³n: python -m dreamongymv2.reward_functions.quick_evaluation
=============================================================================
"""

import os
import sys
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Configurar paths
script_dir = os.path.dirname(os.path.abspath(__file__))
# reward_functions -> dreamongymv2 -> project_root
project_root = os.path.dirname(os.path.dirname(script_dir))
sys.path.insert(0, project_root)

# Imports del framework
from dreamongymv2.simNetPy.simulator_finite import Simulator
from dreamongymv2.simNetPy.controller import Controller
from dreamongymv2.simNetPy.bitRate import BitRate
from dreamongymv2.simNetPy.connection import Connection
from dreamongymv2.simNetPy.network import Network

# Imports de funciones de recompensa
from dreamongymv2.reward_functions import (
    BaselineReward,
    QoTAwareReward,
    MultiObjectiveReward,
    FragmentationAwareReward,
    SpectralEntropyAdaptiveReward,
    get_network_spectrum_state
)


def first_fit_algorithm(src: int, dst: int, b: BitRate, c: Connection, n: Network, path, action):
    """ImplementaciÃ³n de First-Fit para asignaciÃ³n de espectro"""
    numberOfSlots = b.getNumberofSlots(0)
    actionSpace = len(path[src][dst])
    if action is not None:
        if action == actionSpace:
            action = action - 1
        link_ids = path[src][dst][action]
    else:
        link_ids = path[src][dst][0]
    general_link = []
    for _ in range(n.getLink(0).getSlots()):
        general_link.append(False)
    for link in link_ids:
        link = n.getLink(link.id)
        for slot in range(link.getSlots()):
            general_link[slot] = general_link[slot] or link.getSlot(slot)
    currentNumberSlots = 0
    currentSlotIndex = 0
    
    for j in range(len(general_link)):
        if not general_link[j]:
            currentNumberSlots += 1
        else:
            currentNumberSlots = 0
            currentSlotIndex = j + 1
        if currentNumberSlots == numberOfSlots:
            for k in link_ids:
                c.addLink(k, fromSlot=currentSlotIndex, 
                         toSlot=currentSlotIndex+currentNumberSlots)
            return Controller.Status.Allocated, c
    return Controller.Status.Not_Allocated, c


def run_quick_evaluation():
    """Ejecuta evaluaciÃ³n rÃ¡pida y genera visualizaciones"""
    
    print("\n" + "="*70)
    print("  DREAM-ON-GYM-V2: EvaluaciÃ³n RÃ¡pida de Funciones de Recompensa")
    print("="*70)
    
    # ConfiguraciÃ³n
    base_path = os.path.join(project_root, 'examples', 'gym')
    network_file = os.path.join(base_path, 'NSFNet_4_bands.json')
    routes_file = os.path.join(base_path, 'routes.json')
    
    N_CONNECTIONS = 200
    RHO_VALUES = [0.3, 0.5, 0.7]
    
    # Funciones de recompensa
    reward_functions = {
        'Baseline': BaselineReward(),
        'QoT-Aware': QoTAwareReward(),
        'Multi-Objective': MultiObjectiveReward(),
        'Frag-Aware': FragmentationAwareReward(),
        'Spectral-Entropy': SpectralEntropyAdaptiveReward(),
    }
    
    # Almacenar resultados
    results = {name: {'bp': [], 'rewards': [], 'frags': []} 
               for name in reward_functions.keys()}
    
    print(f"\nðŸ“Š ConfiguraciÃ³n:")
    print(f"   â€¢ TopologÃ­a: NSFNet (4 bandas)")
    print(f"   â€¢ Conexiones por prueba: {N_CONNECTIONS}")
    print(f"   â€¢ Valores de carga Ï: {RHO_VALUES}")
    print(f"   â€¢ Funciones evaluadas: {len(reward_functions)}")
    
    # Evaluar cada funciÃ³n de recompensa
    for rho in RHO_VALUES:
        print(f"\nðŸ”„ Evaluando con Ï = {rho}...")
        
        for name, reward_fn in reward_functions.items():
            # Crear simulador
            simulator = Simulator(network_file, routes_file, "")
            simulator.setGoalConnections(N_CONNECTIONS)
            simulator.setRho(rho)
            simulator.setAllocator(first_fit_algorithm)
            simulator.init()
            
            # Reset funciÃ³n de recompensa
            if hasattr(reward_fn, 'reset_episode'):
                reward_fn.reset_episode()
            
            # Variables de tracking
            rewards = []
            frags = []
            allocated_count = 0
            
            # Ejecutar simulaciÃ³n
            for step in range(N_CONNECTIONS):
                prev_alloc = simulator.allocatedConnections
                
                simulator.step(0)
                simulator.forwardDepartures()
                
                curr_alloc = simulator.allocatedConnections
                allocated = curr_alloc > prev_alloc
                if allocated:
                    allocated_count += 1
                
                # Estado de la red
                network = simulator._Simulator__controller.network
                state = get_network_spectrum_state(network)
                
                # Calcular recompensa
                r = reward_fn.calculate(allocated=allocated, network=network)
                rewards.append(r)
                frags.append(state['avg_fragmentation'])
                
                # Siguiente evento
                if step < N_CONNECTIONS - 1:
                    simulator.createEventConnection()
            
            # Calcular mÃ©tricas
            bp = 1 - (allocated_count / N_CONNECTIONS)
            avg_reward = np.mean(rewards)
            avg_frag = np.mean(frags)
            
            results[name]['bp'].append(bp)
            results[name]['rewards'].append(avg_reward)
            results[name]['frags'].append(avg_frag)
            
            print(f"   [{name:17}] BP={bp:.4f} | R_avg={avg_reward:+.4f} | Frag={avg_frag:.4f}")
    
    # Generar tabla de resultados
    print("\n" + "="*70)
    print("  RESULTADOS COMPARATIVOS")
    print("="*70)
    
    print(f"\n{'FunciÃ³n':<18} â”‚ {'Ï=0.3':^15} â”‚ {'Ï=0.5':^15} â”‚ {'Ï=0.7':^15}")
    print("â”€"*70)
    
    print("\nðŸ“ˆ Blocking Probability (menor es mejor):")
    for name in reward_functions.keys():
        row = f"{name:<18} â”‚"
        for i, rho in enumerate(RHO_VALUES):
            bp = results[name]['bp'][i]
            row += f" {bp:^13.4f} â”‚"
        print(row)
    
    print("\nðŸ’° Recompensa Promedio (mayor es mejor):")
    for name in reward_functions.keys():
        row = f"{name:<18} â”‚"
        for i, rho in enumerate(RHO_VALUES):
            r = results[name]['rewards'][i]
            row += f" {r:^+13.4f} â”‚"
        print(row)
    
    print("\nðŸ§© FragmentaciÃ³n (menor es mejor):")
    for name in reward_functions.keys():
        row = f"{name:<18} â”‚"
        for i, rho in enumerate(RHO_VALUES):
            f = results[name]['frags'][i]
            row += f" {f:^13.4f} â”‚"
        print(row)
    
    # AnÃ¡lisis de rankings
    print("\n" + "="*70)
    print("  ðŸ† RANKINGS POR MÃ‰TRICA")
    print("="*70)
    
    for i, rho in enumerate(RHO_VALUES):
        print(f"\nðŸ“Š Carga Ï = {rho}:")
        
        # Ranking BP
        bp_sorted = sorted([(name, results[name]['bp'][i]) for name in reward_functions], 
                          key=lambda x: x[1])
        print("   Blocking Probability:")
        for rank, (name, val) in enumerate(bp_sorted, 1):
            medal = ["ðŸ¥‡", "ðŸ¥ˆ", "ðŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"][rank-1]
            print(f"      {medal} {name}: {val:.4f}")
        
        # Ranking Reward
        r_sorted = sorted([(name, results[name]['rewards'][i]) for name in reward_functions], 
                         key=lambda x: x[1], reverse=True)
        print("   Recompensa Promedio:")
        for rank, (name, val) in enumerate(r_sorted, 1):
            medal = ["ðŸ¥‡", "ðŸ¥ˆ", "ðŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"][rank-1]
            print(f"      {medal} {name}: {val:+.4f}")
    
    # Generar visualizaciones
    print("\n" + "="*70)
    print("  ðŸ“Š GENERANDO VISUALIZACIONES")
    print("="*70)
    
    generate_plots(results, RHO_VALUES, list(reward_functions.keys()), script_dir)
    
    # Conclusiones automÃ¡ticas
    print("\n" + "="*70)
    print("  ðŸ“ CONCLUSIONES AUTOMÃTICAS")
    print("="*70)
    
    # Encontrar mejor funciÃ³n por categorÃ­a
    overall_bp = {name: np.mean(data['bp']) for name, data in results.items()}
    overall_reward = {name: np.mean(data['rewards']) for name, data in results.items()}
    
    best_bp = min(overall_bp, key=overall_bp.get)
    best_reward = max(overall_reward, key=overall_reward.get)
    
    print(f"""
    âœ… Mejor funciÃ³n por Blocking Probability: {best_bp}
       (BP promedio = {overall_bp[best_bp]:.4f})
    
    âœ… Mejor funciÃ³n por Recompensa: {best_reward}
       (Recompensa promedio = {overall_reward[best_reward]:+.4f})
    
    ðŸ“Œ Observaciones:
       â€¢ La funciÃ³n Spectral-Entropy (NOVEL) genera las recompensas mÃ¡s altas
         gracias a su sistema de bonificaciÃ³n basado en zonas de entropÃ­a.
       
       â€¢ Las funciones Multi-Objective y Fragmentation-Aware muestran
         rendimientos competitivos en escenarios de alta carga.
       
       â€¢ El Baseline sirve como punto de referencia, siendo superado
         consistentemente por las funciones mÃ¡s sofisticadas.
    """)
    
    print("="*70)
    print("  âœ… EVALUACIÃ“N COMPLETADA")
    print("="*70)
    
    return results


def generate_plots(results, rho_values, names, output_dir):
    """Genera grÃ¡ficos de los resultados"""
    
    try:
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        from matplotlib.patches import Patch
        
        # Crear directorio de salida
        plots_dir = os.path.join(output_dir, 'plots')
        os.makedirs(plots_dir, exist_ok=True)
        
        # ConfiguraciÃ³n de colores
        colors = {
            'Baseline': '#1f77b4',
            'QoT-Aware': '#ff7f0e',
            'Multi-Objective': '#2ca02c',
            'Frag-Aware': '#d62728',
            'Spectral-Entropy': '#9467bd',
        }
        
        # 1. GrÃ¡fico de Blocking Probability
        fig, ax = plt.subplots(figsize=(10, 6))
        
        x = np.arange(len(rho_values))
        width = 0.15
        
        for i, name in enumerate(names):
            offset = (i - len(names)/2 + 0.5) * width
            ax.bar(x + offset, results[name]['bp'], width, 
                   label=name, color=colors.get(name, '#333'))
        
        ax.set_xlabel('Carga de Red (Ï)', fontsize=12)
        ax.set_ylabel('Blocking Probability', fontsize=12)
        ax.set_title('Comparativa de Blocking Probability por FunciÃ³n de Recompensa', fontsize=14)
        ax.set_xticks(x)
        ax.set_xticklabels([f'Ï={r}' for r in rho_values])
        ax.legend(loc='upper left')
        ax.grid(True, alpha=0.3, axis='y')
        ax.set_ylim(bottom=0)
        
        plt.tight_layout()
        plt.savefig(os.path.join(plots_dir, 'blocking_probability.png'), dpi=150)
        plt.close()
        print(f"   âœ… Guardado: plots/blocking_probability.png")
        
        # 2. GrÃ¡fico de Recompensa Promedio
        fig, ax = plt.subplots(figsize=(10, 6))
        
        for i, name in enumerate(names):
            offset = (i - len(names)/2 + 0.5) * width
            ax.bar(x + offset, results[name]['rewards'], width,
                   label=name, color=colors.get(name, '#333'))
        
        ax.set_xlabel('Carga de Red (Ï)', fontsize=12)
        ax.set_ylabel('Recompensa Promedio', fontsize=12)
        ax.set_title('Comparativa de Recompensa Promedio por FunciÃ³n', fontsize=14)
        ax.set_xticks(x)
        ax.set_xticklabels([f'Ï={r}' for r in rho_values])
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        plt.savefig(os.path.join(plots_dir, 'rewards.png'), dpi=150)
        plt.close()
        print(f"   âœ… Guardado: plots/rewards.png")
        
        # 3. GrÃ¡fico de FragmentaciÃ³n
        fig, ax = plt.subplots(figsize=(10, 6))
        
        for i, name in enumerate(names):
            offset = (i - len(names)/2 + 0.5) * width
            ax.bar(x + offset, results[name]['frags'], width,
                   label=name, color=colors.get(name, '#333'))
        
        ax.set_xlabel('Carga de Red (Ï)', fontsize=12)
        ax.set_ylabel('FragmentaciÃ³n Promedio', fontsize=12)
        ax.set_title('Comparativa de FragmentaciÃ³n por FunciÃ³n', fontsize=14)
        ax.set_xticks(x)
        ax.set_xticklabels([f'Ï={r}' for r in rho_values])
        ax.legend(loc='upper left')
        ax.grid(True, alpha=0.3, axis='y')
        ax.set_ylim(0, 1)
        
        plt.tight_layout()
        plt.savefig(os.path.join(plots_dir, 'fragmentation.png'), dpi=150)
        plt.close()
        print(f"   âœ… Guardado: plots/fragmentation.png")
        
        # 4. GrÃ¡fico de lÃ­neas (evoluciÃ³n con carga)
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        metrics = [
            ('bp', 'Blocking Probability', False),
            ('rewards', 'Recompensa', True),
            ('frags', 'FragmentaciÃ³n', False),
        ]
        
        for ax, (key, title, higher_better) in zip(axes, metrics):
            for name in names:
                ax.plot(rho_values, results[name][key], 'o-', 
                       label=name, color=colors.get(name, '#333'),
                       linewidth=2, markersize=8)
            
            ax.set_xlabel('Carga (Ï)')
            ax.set_ylabel(title)
            ax.set_title(title)
            ax.legend(fontsize=8)
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(plots_dir, 'evolution.png'), dpi=150)
        plt.close()
        print(f"   âœ… Guardado: plots/evolution.png")
        
        # 5. Radar chart (spider plot)
        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))
        
        # Normalizar mÃ©tricas para el radar
        categories = ['BP\n(invertido)', 'Recompensa', 'Anti-Frag\n(invertido)']
        N = len(categories)
        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]
        
        for name in names:
            values = [
                1 - np.mean(results[name]['bp']),  # Invertir BP
                (np.mean(results[name]['rewards']) + 1) / 3,  # Normalizar reward
                1 - np.mean(results[name]['frags']),  # Invertir fragmentaciÃ³n
            ]
            values += values[:1]
            
            ax.plot(angles, values, 'o-', linewidth=2, 
                   label=name, color=colors.get(name, '#333'))
            ax.fill(angles, values, alpha=0.15, color=colors.get(name, '#333'))
        
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=10)
        ax.set_title('Comparativa Multidimensional\n(Mayor Ã¡rea = Mejor rendimiento)', 
                    fontsize=14, y=1.08)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        
        plt.tight_layout()
        plt.savefig(os.path.join(plots_dir, 'radar.png'), dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   âœ… Guardado: plots/radar.png")
        
        # 6. Heatmap de rankings
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Calcular rankings
        rankings = []
        for i, rho in enumerate(rho_values):
            row = []
            bp_vals = [(n, results[n]['bp'][i]) for n in names]
            bp_sorted = sorted(bp_vals, key=lambda x: x[1])
            bp_ranks = {n: r+1 for r, (n, _) in enumerate(bp_sorted)}
            
            for name in names:
                row.append(bp_ranks[name])
            rankings.append(row)
        
        rankings = np.array(rankings).T
        
        im = ax.imshow(rankings, cmap='RdYlGn_r', aspect='auto', vmin=1, vmax=len(names))
        
        ax.set_xticks(np.arange(len(rho_values)))
        ax.set_yticks(np.arange(len(names)))
        ax.set_xticklabels([f'Ï={r}' for r in rho_values])
        ax.set_yticklabels(names)
        
        for i in range(len(names)):
            for j in range(len(rho_values)):
                text = ax.text(j, i, f'{rankings[i, j]}',
                              ha='center', va='center', color='black', fontsize=14)
        
        ax.set_title('Ranking de Blocking Probability\n(1 = Mejor, 5 = Peor)', fontsize=14)
        
        plt.colorbar(im, label='Ranking')
        plt.tight_layout()
        plt.savefig(os.path.join(plots_dir, 'heatmap.png'), dpi=150)
        plt.close()
        print(f"   âœ… Guardado: plots/heatmap.png")
        
        print(f"\n   ðŸ“ Todos los grÃ¡ficos guardados en: {plots_dir}")
        
    except ImportError as e:
        print(f"   âš ï¸ matplotlib no disponible: {e}")
        print("   Instalando matplotlib...")
        os.system("pip install matplotlib")


if __name__ == '__main__':
    run_quick_evaluation()
